{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QhALvlw4QxO"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTOa3E8L4QxP"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzyP4b-84QxP"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCQt2fnc4QxR",
        "outputId": "bf36733f-9c27-4af9-fcb1-f737ab657a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmXnJtXc4QxX"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4yiJgvl4QxX"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "4n8oJybq4QxX",
        "outputId": "315a0e55-20f1-43c4-bf3b-a191c86dc2b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGt72Z1g4QxY"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V_xgWwL4QxY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMN8mfY-4QxY"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3nqvunX4Qxa",
        "outputId": "a4745d39-534a-4b9c-ba97-27a4ac61af71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255.\n",
        "X_test_norm = X_test/255.\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "print(np.shape(X_train_norm))\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_train_norm))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqfxg49z4Qxc"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP5wEH7y4Qxc",
        "outputId": "1c9c5a23-6ec3-4cf2-9704-48878308612d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim=input_dim, activation=\"sigmoid\"))\n",
        "    model.add(Dense(10, activation=\"sigmoid\"))\n",
        "    \n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4UFRagf4Qxc"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmp9OOOw4Qxc",
        "outputId": "8eec3e50-05d6-48f0-8a37-de5c4df769f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.9617 - accuracy: 0.4729\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.2697 - accuracy: 0.6770\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9338 - accuracy: 0.7383\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7746 - accuracy: 0.7704\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6690 - accuracy: 0.7998\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.8202\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5436 - accuracy: 0.8302\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5095 - accuracy: 0.8362\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4856 - accuracy: 0.8410\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8447\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.8476\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8496\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4331 - accuracy: 0.8514\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4253 - accuracy: 0.8551\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8567\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8587\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4055 - accuracy: 0.8602\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3999 - accuracy: 0.8621\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3959 - accuracy: 0.8624\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3910 - accuracy: 0.8645\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8644\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8664\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3811 - accuracy: 0.8681\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8686\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3739 - accuracy: 0.8697\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3720 - accuracy: 0.8703\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8728\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3666 - accuracy: 0.8729\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3646 - accuracy: 0.8728\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8736\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3610 - accuracy: 0.8738\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3586 - accuracy: 0.8746\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8748\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3550 - accuracy: 0.8757\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8773\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3516 - accuracy: 0.8768\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8770\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3482 - accuracy: 0.8776\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3476 - accuracy: 0.8788\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8788\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8805\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8792\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8803\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3405 - accuracy: 0.8807\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8802\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8807\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8813\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3351 - accuracy: 0.8822\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3345 - accuracy: 0.8826\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8825\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8826\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8815\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8840\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8841\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8832\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8838\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8842\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3266 - accuracy: 0.8844\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3248 - accuracy: 0.8855\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8849\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8854\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8852\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8860\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3221 - accuracy: 0.8867\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8851\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8865\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.8876\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8861\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3174 - accuracy: 0.8880\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3175 - accuracy: 0.8874\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3171 - accuracy: 0.8873\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3164 - accuracy: 0.8878\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8887\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8882\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8889\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8887\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8886\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3124 - accuracy: 0.8892\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3118 - accuracy: 0.8887\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3113 - accuracy: 0.8888\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3119 - accuracy: 0.8884\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.8894\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.8899\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8903\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.8902\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3083 - accuracy: 0.8903\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3071 - accuracy: 0.8906\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3062 - accuracy: 0.8911\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8900\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8903\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8921\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8906\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.8916\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8920\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8913\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8923\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.8925\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3022 - accuracy: 0.8928\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8923\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.8924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e0dbe2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhLrDTtt4Qxd"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15i324Eq4Qxd",
        "outputId": "cdd16e7b-c266-4a2f-e0ee-a469df2c3929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8949333429336548\n",
            "accuracy on test with NN: 0.8561999797821045\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HJPJ6WT4Qxd"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifJXolY24Qxd"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imrkomJ64Qxd"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q73PxWhv4Qxe"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_hzDCcFz4Qxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca42085-9139-4163-ba5a-7259586a5eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on test 0.8618\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on test', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t9gppEO4Qxe"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLquW-U64Qxe"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}